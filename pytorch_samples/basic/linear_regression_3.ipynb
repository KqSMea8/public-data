{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 生成一批训练数据\n",
    "y = ax + b (不加b，只有一个a的话，损失函数可以用个平面搞出来？)\n",
    "\n",
    "设a=2, b=1, 可以产生一批数据\n",
    "x=1.1, y=3.2\n",
    "x=1.2, y=3.4\n",
    "x=1.3, y=3.7\n",
    "...\n",
    "\n",
    "可以使用for循环生成这批数据，但使用numpy 或 pytorch的广播机制更方便、性能也更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5690],\n",
      "        [0.9634],\n",
      "        [0.0962],\n",
      "        [0.0071],\n",
      "        [0.9956],\n",
      "        [0.4627],\n",
      "        [0.8271],\n",
      "        [0.6023],\n",
      "        [0.2810],\n",
      "        [0.5355]]) torch.Size([10, 1])\n",
      "tensor([[2.1379],\n",
      "        [2.9268],\n",
      "        [1.1924],\n",
      "        [1.0143],\n",
      "        [2.9912],\n",
      "        [1.9255],\n",
      "        [2.6541],\n",
      "        [2.2047],\n",
      "        [1.5620],\n",
      "        [2.0711]]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "m = 10 #样本数量\n",
    "x = torch.rand(m,1)\n",
    "print(x,x.shape)\n",
    "\n",
    "y = x*2 + 1 # y = ax + b\n",
    "print(y,y.shape) #使用pytorch的广播机制更方便、性能也更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#图像表示？\n",
    "plt.plot(x.view(-1,1).numpy(),y.view(-1,1).numpy())\n",
    "# plt.plot(x.numpy(),y.numpy()) #ValueError: x and y must be the same size\n",
    "plt.scatter(x,y,c = 'r',marker = 'o') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 正向传播\n",
    "假设一开始我们并不知道a和b的值是多少，只有很多很多的x,y值，如何从这些数据中确定a和b的值？\n",
    "\n",
    "先假设一个a和b的值，例如设置a=0.1,b=0.2, 根据式子y=ax+b, 可以计算出, 预测的y值是多少，\n",
    "\n",
    "通过比较这个预测的y值和真实的y值差多少，例如一点都不差，a,b的值就对了，如果还有差别，就需要继续调整a,b的值。\n",
    "\n",
    "如何比较，预测值与真实值之间的差距呢，平方误差函数 sum( (y-pre_y)**2  )/m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2749],\n",
      "        [0.2999],\n",
      "        [0.2590],\n",
      "        [0.2146],\n",
      "        [0.2927],\n",
      "        [0.2060],\n",
      "        [0.2692],\n",
      "        [0.2859],\n",
      "        [0.2129],\n",
      "        [0.2825]]) torch.Size([10, 1])\n",
      "tensor([[2.2223],\n",
      "        [2.6974],\n",
      "        [1.9212],\n",
      "        [1.0771],\n",
      "        [2.5619],\n",
      "        [0.9138],\n",
      "        [2.1154],\n",
      "        [2.4319],\n",
      "        [1.0454],\n",
      "        [2.3670]])\n",
      "tensor([[4.9388],\n",
      "        [7.2761],\n",
      "        [3.6909],\n",
      "        [1.1601],\n",
      "        [6.5636],\n",
      "        [0.8350],\n",
      "        [4.4748],\n",
      "        [5.9140],\n",
      "        [1.0929],\n",
      "        [5.6025]])\n",
      "tensor(41.5487)\n",
      "tensor(4.1549)\n",
      "tensor(4.1549)\n",
      "tensor(4.1549)\n"
     ]
    }
   ],
   "source": [
    "pre_y = x*0.1 + 0.2\n",
    "print(pre_y,pre_y.size())\n",
    "\n",
    "print ( y-pre_y )\n",
    "print( (y-pre_y)**2 )\n",
    "print( torch.sum((y-pre_y)**2) ) \n",
    "\n",
    "print( torch.sum((y-pre_y)**2)/m ) # sum( (ax+b - y) **2 )/m\n",
    "print( torch.mean((y-pre_y)**2) )   # sum( (ax+b - y) **2 )/m\n",
    "\n",
    "l = torch.nn.functional.mse_loss(y,pre_y) #等价上面2中表示方式\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4647)\n",
      "tensor(1.0536)\n",
      "tensor(0.0060)\n"
     ]
    }
   ],
   "source": [
    "# 可以手动调整a,b的值，观察当a,b接近真实值时，损失函数接近与0\n",
    "l = torch.nn.functional.mse_loss(y,x*0.8 + 0.2)  \n",
    "print(l)\n",
    "\n",
    "l = torch.nn.functional.mse_loss(y,x*0.9 + 0.7)  \n",
    "print(l)\n",
    "\n",
    "l = torch.nn.functional.mse_loss(y,x*1.9 + 0.99)  \n",
    "print(l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 反向传播\n",
    "如何根据真实值与预估值之间的差距来调整a,b值呢？\n",
    "\n",
    "梯度下降，损失函数的直观图示？\n",
    "\n",
    "对损失函数求导:\n",
    "\n",
    "(ax+b - y) * * 2  （复合函数求导 L= (f(x) -y) ** 2 ）\n",
    "a的偏导: 2(ax + b - y)*x\n",
    "b的偏导: 2(ax+b - y)\n",
    "\n",
    "a:= a - lrate*d(a)\n",
    "b:= b - lrage*d(b)\n",
    "\n",
    "pytorch的反向传播机制？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3823)\n",
      "tensor(-0.4880)\n"
     ]
    }
   ],
   "source": [
    "pre_y = x*1.2 + 0.99\n",
    "da=torch.mean( ( pre_y - y)*x)\n",
    "print(da)\n",
    "db = torch.mean( (pre_y - y))\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0253) tensor(0.0318) tensor(5.1976)\n",
      "tensor(1.3711) tensor(1.4072) tensor(0.0459)\n",
      "tensor(1.5826) tensor(1.2716) tensor(0.0203)\n",
      "tensor(1.7225) tensor(1.1806) tensor(0.0090)\n",
      "tensor(1.8155) tensor(1.1200) tensor(0.0040)\n",
      "tensor(1.8774) tensor(1.0798) tensor(0.0017)\n",
      "tensor(1.9185) tensor(1.0530) tensor(0.0008)\n",
      "tensor(1.9458) tensor(1.0353) tensor(0.0003)\n",
      "tensor(1.9640) tensor(1.0234) tensor(0.0002)\n",
      "tensor(1.9761) tensor(1.0156) tensor(0.0001)\n",
      "tensor(1.9841) tensor(1.0104) tensor(0.0000)\n",
      "tensor(1.9894) tensor(1.0069) tensor(0.0000)\n",
      "tensor(1.9930) tensor(1.0046) tensor(5.7562e-06)\n",
      "tensor(1.9953) tensor(1.0030) tensor(2.5449e-06)\n",
      "tensor(1.9969) tensor(1.0020) tensor(1.1259e-06)\n",
      "tensor(1.9979) tensor(1.0013) tensor(4.9894e-07)\n",
      "tensor(1.9986) tensor(1.0009) tensor(2.2194e-07)\n",
      "tensor(1.9991) tensor(1.0006) tensor(9.9335e-08)\n",
      "tensor(1.9994) tensor(1.0004) tensor(4.4876e-08)\n",
      "tensor(1.9996) tensor(1.0003) tensor(2.0412e-08)\n"
     ]
    }
   ],
   "source": [
    "#迭代，求a和b的值\n",
    "\n",
    "a=0.01\n",
    "b=0.01\n",
    "learning_rate = 0.01\n",
    "\n",
    "for i in range(10000):\n",
    "    pre_y = x*a + b\n",
    "    tmp_a = a - learning_rate*torch.mean( (pre_y - y)*x)\n",
    "    tmp_b = b - learning_rate*torch.mean( (pre_y - y))\n",
    "    a = tmp_a\n",
    "    b = tmp_b\n",
    "    if i%500 == 0:\n",
    "        cost = torch.nn.functional.mse_loss(y,pre_y) \n",
    "        print(a,b,cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 多特征的情况，特征和权重都用向量操作\n",
    "y = w1*x1 + w2*x2 + w3*x3 + ... + b\n",
    "\n",
    "y = X.WT + b\n",
    "\n",
    "y = X.Wt (x尾部增加一列1，把b放入W) #pytorch是这样的么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.2189],\n",
      "        [12.0847],\n",
      "        [11.8360],\n",
      "        [11.8297],\n",
      "        [11.3446],\n",
      "        [11.2870],\n",
      "        [11.6242],\n",
      "        [12.0731],\n",
      "        [11.7695],\n",
      "        [11.9022]])\n",
      "tensor([[11.2189],\n",
      "        [12.0847],\n",
      "        [11.8360],\n",
      "        [11.8297],\n",
      "        [11.3446],\n",
      "        [11.2870],\n",
      "        [11.6242],\n",
      "        [12.0731],\n",
      "        [11.7695],\n",
      "        [11.9022]])\n"
     ]
    }
   ],
   "source": [
    "m = 10 #样本数量\n",
    "n = 5 # 特征数量\n",
    "b = 10 \n",
    "x = torch.rand(m,n)\n",
    "#print(x)\n",
    "w = torch.rand(1,n)\n",
    "#print(w)\n",
    "y = x.matmul(torch.t(w)) + b\n",
    "print(y)\n",
    "\n",
    "y = torch.mm(x,torch.t(w)) + b #torch.mm 等价 x.matmul\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8168, 0.3197, 0.2967, 0.0579, 0.2479, 1.0000],\n",
      "        [0.9049, 0.4754, 0.5885, 0.5183, 0.9407, 1.0000],\n",
      "        [0.7813, 0.1585, 0.4884, 0.7606, 0.4192, 1.0000],\n",
      "        [0.4551, 0.5130, 0.5467, 0.7839, 0.5705, 1.0000],\n",
      "        [0.4457, 0.0918, 0.2462, 0.8089, 0.2406, 1.0000],\n",
      "        [0.1712, 0.3619, 0.8802, 0.2749, 0.7154, 1.0000],\n",
      "        [0.6962, 0.1161, 0.9439, 0.1760, 0.9793, 1.0000],\n",
      "        [0.9989, 0.1604, 0.6464, 0.7280, 0.2005, 1.0000],\n",
      "        [0.9422, 0.2610, 0.7257, 0.2013, 0.6927, 1.0000],\n",
      "        [0.4168, 0.6678, 0.7353, 0.6170, 0.7851, 1.0000]])\n",
      "tensor([[10.]])\n",
      "tensor([[ 0.9170,  0.5936,  0.6385,  0.8452,  0.1689, 10.0000]])\n",
      "tensor([[11.2189],\n",
      "        [12.0847],\n",
      "        [11.8360],\n",
      "        [11.8297],\n",
      "        [11.3446],\n",
      "        [11.2870],\n",
      "        [11.6242],\n",
      "        [12.0731],\n",
      "        [11.7695],\n",
      "        [11.9022]])\n"
     ]
    }
   ],
   "source": [
    "one = torch.ones(m,1)\n",
    "# print(one)\n",
    "x1 = torch.cat([x,one],-1)\n",
    "print(x1) \n",
    "b1 = torch.tensor([[b]],dtype=torch.float)\n",
    "print(b1)\n",
    "w1 = torch.cat([w,b1],-1)\n",
    "print(w1)\n",
    "y1 = torch.mm(x1,torch.t(w1))\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 3.5000, 4.5000]) tensor([2., 5.])\n",
      "tensor([[2.],\n",
      "        [5.]])\n",
      "tensor([[2.],\n",
      "        [5.]])\n"
     ]
    }
   ],
   "source": [
    "# 测试下torch.mean的用法\n",
    "test_mean = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float)\n",
    "m0 = torch.mean(test_mean,0)\n",
    "m1 = torch.mean(test_mean,1)#\n",
    "print(m0,m1)\n",
    "print(m1.view(-1,1))\n",
    "m2 = torch.mean(test_mean,1,keepdim=True)\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: tensor([[ 0.9170,  0.5936,  0.6385,  0.8452,  0.1689, 10.0000]])\n",
      "w_x: tensor([[0.3550, 0.2091, 0.7915, 0.3652, 0.7814, 0.7845]])\n",
      "tensor([[0.4183, 0.2387, 0.8490, 0.4125, 0.8358, 0.8795]]) tensor(90.2731)\n",
      "tensor([[2.6514, 1.1768, 2.0964, 2.4906, 1.0632, 6.3819]]) tensor(0.4001)\n",
      "tensor([[2.1531, 1.1432, 1.8145, 2.0063, 0.4938, 7.4868]]) tensor(0.1850)\n",
      "tensor([[1.7862, 1.0985, 1.6190, 1.6283, 0.2151, 8.2252]]) tensor(0.0897)\n",
      "tensor([[1.5334, 1.0422, 1.4544, 1.3731, 0.0681, 8.7310]]) tensor(0.0454)\n",
      "tensor([[ 1.3592,  0.9829,  1.3145,  1.2031, -0.0030,  9.0816]]) tensor(0.0241)\n",
      "tensor([[ 1.2381,  0.9260,  1.1965,  1.0898, -0.0295,  9.3272]]) tensor(0.0135)\n",
      "tensor([[ 1.1530,  0.8741,  1.0977,  1.0138, -0.0306,  9.5011]]) tensor(0.0078)\n",
      "tensor([[ 1.0925,  0.8282,  1.0155,  0.9626, -0.0182,  9.6257]]) tensor(0.0047)\n",
      "tensor([[1.0491, 0.7887, 0.9474, 0.9278, 0.0005, 9.7160]]) tensor(0.0029)\n",
      "tensor([[1.0175, 0.7550, 0.8913, 0.9041, 0.0214, 9.7823]]) tensor(0.0019)\n",
      "tensor([[0.9942, 0.7266, 0.8451, 0.8876, 0.0421, 9.8316]]) tensor(0.0012)\n",
      "tensor([[0.9769, 0.7030, 0.8072, 0.8762, 0.0613, 9.8687]]) tensor(0.0008)\n",
      "tensor([[0.9638, 0.6833, 0.7762, 0.8681, 0.0785, 9.8968]]) tensor(0.0005)\n",
      "tensor([[0.9538, 0.6670, 0.7508, 0.8623, 0.0935, 9.9185]]) tensor(0.0003)\n",
      "tensor([[0.9461, 0.6536, 0.7300, 0.8581, 0.1063, 9.9353]]) tensor(0.0002)\n",
      "tensor([[0.9402, 0.6426, 0.7130, 0.8551, 0.1172, 9.9483]]) tensor(0.0001)\n",
      "tensor([[0.9355, 0.6336, 0.6992, 0.8528, 0.1263, 9.9586]]) tensor(0.0001)\n"
     ]
    }
   ],
   "source": [
    "print('w1:',w1)\n",
    "\n",
    "w_x = torch.rand_like(w1)\n",
    "print('w_x:',w_x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "for i in range(35000):\n",
    "    pre_y = torch.mm(x1,torch.t(w_x))\n",
    "#     print(pre_y)\n",
    "    \n",
    "    ld = (pre_y - y1)*x1\n",
    "#     print(ld)\n",
    "#     print(\"dim0:\",torch.mean(ld,0))\n",
    "#     print(\"dim1:\",torch.mean(ld,1))\n",
    "    w_x = w_x - learning_rate*torch.mean( ld ,0)  \n",
    "#     w_x = tmp_w  #\n",
    "    \n",
    "    if i%2000 == 0:\n",
    "        cost = torch.nn.functional.mse_loss(y1,pre_y) \n",
    "        print(w_x,cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
