{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xor异或, 2个输入中有一个为1但不全为1，结果是1，其他情况0。线性不可分\n",
    "# 不使用placeholder的代码\n",
    "# https://aimatters.wordpress.com/2016/01/16/solving-xor-with-a-neural-network-in-tensorflow/\n",
    "# https://github.com/StephenOman/TensorFlowExamples/blob/master/xor%20nn/xor_nn.py\n",
    "\n",
    "#  \n",
    "# http://blog.csdn.net/u011026968/article/details/72084273\n",
    "  \n",
    "# https://gist.github.com/pannous/2b8e2e05cf05a630b132\n",
    "# https://github.com/techdisrupt/XOR/blob/master/xor.py\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name = \"Theta1\")\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name = \"Bias1\")\n",
    "\n",
    "Theta2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name = \"Theta2\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name = \"Bias2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs():\n",
    "    \"\"\"输入\"\"\"\n",
    "    XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "    XOR_Y = [[0],[1],[1],[0]]\n",
    "    return tf.to_float(XOR_X), tf.to_float(XOR_Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_inputs(X):\n",
    "    return tf.matmul(X,W) + b\n",
    "\n",
    "def inference(X):\n",
    "    \"\"\"推断模型\n",
    "    加入了隐藏层\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"layer2\") as scope:\n",
    "        A2 = tf.sigmoid(tf.matmul(X, Theta1) + Bias1)\n",
    "\n",
    "    with tf.name_scope(\"layer3\") as scope:\n",
    "        Hypothesis = tf.sigmoid(tf.matmul(A2, Theta2) + Bias2)\n",
    "        \n",
    "    return Hypothesis\n",
    "\n",
    "def loss(X,Y):\n",
    "    \"\"\"损失函数\"\"\"\n",
    "    with tf.name_scope(\"cost\") as scope:\n",
    "        Hypothesis = inference(X)  \n",
    "        return tf.reduce_mean(( (Y * tf.log(Hypothesis)) + ((1 - Y) * tf.log(1.0 - Hypothesis)) ) * -1) \n",
    "    \n",
    "        #为啥自己实现了一个交叉熵损失函数？ http://geek.csdn.net/news/detail/126833\n",
    "        #return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Hypothesis, labels=Y)) \n",
    "\n",
    "def train(total_loss):\n",
    "    \"\"\"依据 计算的总损失 训练或调整 模型参数\"\"\"\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        learning_rate = 0.05\n",
    "        return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "def evaluate(sess,X,Y):\n",
    "    predicted = tf.cast(inference(X)>0.5,tf.float32)\n",
    "    print( sess.run( tf.reduce_mean( tf.cast( tf.equal(predicted,Y),tf.float32)) ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.ops.nn' has no attribute 'sigmoid_cross_entropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2ffb86f11ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e6df5b79c3da>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         return tf.reduce_mean(( (Y * tf.log(Hypothesis)) + ((1 - Y) * tf.log(1.0 - Hypothesis)) ) * -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#why? http://geek.csdn.net/news/detail/126833\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.ops.nn' has no attribute 'sigmoid_cross_entropy'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs() \n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator() #??\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord) #?\n",
    "    \n",
    "    training_steps = 100000\n",
    "    for step in range(training_steps):\n",
    "        sess.run([train_op])\n",
    "        # for debugging and learning purposes, see how the loss gets decremented thru training steps\n",
    "        if step % 1000 == 0: \n",
    "            print(\"step:%s, loss:%s \" %(step, sess.run([total_loss]))) \n",
    "            \n",
    "\n",
    "    evaluate(sess, X, Y)\n",
    "    print(\"step:%s, W1:%s, b1:%s,  W2:%s, b2:%s, loss:%s \" %(step,sess.run(Theta1),sess.run(Bias1),sess.run(Theta2),sess.run(Bias2), sess.run([total_loss])))\n",
    "    print(\"predicted:%s\"% sess.run(inference(X)))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    #~ tensorboard --logdir=\"./tmp/graph/xor_0\"\n",
    "    writer = tf.summary.FileWriter('./tmp/graph/xor',sess.graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
