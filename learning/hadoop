一、了解原理
1. 输入、计算、输出模型
    数据存储：单个磁盘 -> 磁盘阵列
    计算方式：串行 -> 并行
2. map & reduce
3. hdfs
    文件操作:增删改查等等
    shell &  java api
4. 基本架构，组件 
5. 一般流程
    数据分片、map、reduce
6. 各种异常
    5.1 存储： 节点故障
    5.2 计算： 各种环节的失败

二、实践
1. 安装配置hadoop
2. 搭建java+hadoop的开发环境
    hadoop学习之二:mac下hadoop+eclipse环境搭建
    http://blog.csdn.net/Ruidu_Doer/article/details/50781144
3. 完整走一个基于pyhton的hadoop map Reduce？ 
    基于python的mapreduce开发流程
    http://blog.csdn.net/susser43/article/details/41518831   
4. 下载更多示例代码，试运行
    count,sum,max,min,去重,排序,avg,标准差等
5. 基于hadoop的算法、机器学习等
    《数据算法:Hadoop/Spark大数据处理技巧》

三、思考
1. 很多人并不了解mysql的各种细节，初级能力建表、sql查询等，hadoop教材应该也遵循这个规则，先初级实践，再更深层次的？


hdfs的一般性操作
hdfs的原理，如何保证节点损坏后可用


job - task 

job调度
1. fifo
2. fair scheduler , task 槽的数量，支持【抢占】


shuffle

环形内存缓冲池